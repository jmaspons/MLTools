% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/pipe_keras_timeseries.r
\name{pipe_keras_timeseries}
\alias{pipe_keras_timeseries}
\title{Neural network model with keras}
\usage{
pipe_keras_timeseries(
  df,
  predInput = NULL,
  responseVars = 1,
  caseClass = NULL,
  idVars = character(),
  weight = "class",
  timevar = NULL,
  responseTime = "LAST",
  regex_time = ".+",
  staticVars = NULL,
  crossValStrategy = c("Kfold", "bootstrap"),
  k = 5,
  replicates = 10,
  crossValRatio = c(train = 0.6, test = 0.2, validate = 0.2),
  hidden_shape.RNN = c(32, 32),
  hidden_shape.static = c(32, 32),
  hidden_shape.main = 32,
  epochs = 500,
  maskNA = NULL,
  batch_size = "all",
  repVi = 5,
  perm_dim = 2:3,
  comb_dims = FALSE,
  summarizePred = TRUE,
  scaleDataset = FALSE,
  NNmodel = FALSE,
  DALEXexplainer = FALSE,
  variableResponse = FALSE,
  save_validateset = FALSE,
  baseFilenameNN = NULL,
  filenameRasterPred = NULL,
  tempdirRaster = NULL,
  nCoresRaster = parallel::detectCores()\%/\%2,
  verbose = 0,
  ...
)
}
\arguments{
\item{df}{a \code{data.frame} with the data in a long format (time variable in the \code{timevar} column).}

\item{predInput}{a \code{data.frame} with the input variables to make predictions. The columns names must match the names of \code{df} columns.}

\item{responseVars}{response variables as column names or indexes on \code{df} in wide format (eg. respVar_time).}

\item{caseClass}{class of the samples used to weight cases. Column names or indexes on \code{df}, or a vector with the class for each rows in \code{df}.}

\item{idVars}{id column names or indexes on \code{df}. Should be a unique identifier for a row in wide format, otherwise, values will be averaged.}

\item{weight}{Optional array of the same length as \code{nrow(df)}, containing weights to apply to the model's loss for each sample.}

\item{timevar}{column name of the variable containing the time.}

\item{responseTime}{a \code{timevar} value used as a response var for \code{responseVars} or the default "LAST" for the last timestep available (\code{max(df[, timevar])}).}

\item{regex_time}{regular expression matching the \code{timevar} values format.}

\item{staticVars}{predictor variables as column names or indexes on \code{df} indicating fixed vars that don't change over time.}

\item{crossValStrategy}{\code{Kfold} or \code{bootstrap}.}

\item{k}{number of data partitions when \code{crossValStrategy="Kfold"}.}

\item{replicates}{number of replicates for \code{crossValStrategy="bootstrap"} and \code{crossValStrategy="Kfold"} (\code{replicates * k-1}, 1 fold for validation).}

\item{crossValRatio}{Proportion of the dataset used to train, test and validate the model when \code{crossValStrategy="bootstrap"}. Default to \code{c(train=0.6, test=0.2, validate=0.2)}. If there is only one value, will be taken as a train proportion and the test set will be used for validation.}

\item{hidden_shape.RNN}{number of neurons in the hidden layers of the Recursive Neural Network model (time series data). Can be a vector with values for each hidden layer.}

\item{hidden_shape.static}{number of neurons in the hidden layers of the densely connected neural network model (static data). Can be a vector with values for each hidden layer.}

\item{hidden_shape.main}{number of neurons in the hidden layers of the densely connected neural network model connecting static and time series data. Can be a vector with values for each hidden layer.}

\item{epochs}{parameter for \code{\link[keras:reexports]{keras::fit()}}.}

\item{maskNA}{value to assign to \code{NA}s after scaling and passed to \code{\link[keras:layer_masking]{keras::layer_masking()}}.}

\item{batch_size}{for fit and predict functions. The bigger the better if it fits your available memory. Integer or "all".}

\item{repVi}{replicates of the permutations to calculate the importance of the variables. 0 to avoid calculating variable importance.}

\item{perm_dim}{dimension to perform the permutations to calculate the importance of the variables (data dimensions [case, time, variable]).
If \code{perm_dim = 2:3}, it calculates the importance for each combination of the 2nd and 3rd dimensions.}

\item{comb_dims}{variable importance calculations, if \code{TRUE}, do the permutations for each combination of the levels of the variables from 2nd and 3rd dimensions for input data with 3 dimensions. By default \code{FALSE}.}

\item{summarizePred}{if \code{TRUE}, return the mean, sd and se of the predictors. if \code{FALSE}, return the predictions for each replicate.}

\item{scaleDataset}{if \code{TRUE}, scale the whole dataset only once instead of the train set at each replicate. Optimize processing time for predictions with large rasters.}

\item{NNmodel}{if \code{TRUE}, return the serialized model with the result.}

\item{DALEXexplainer}{if \code{TRUE}, return a explainer for the models from \code{\link[DALEX:explain]{DALEX::explain()}} function. It doesn't work with multisession future plans.}

\item{variableResponse}{if \code{TRUE}, return aggregated_profiles_explainer object from \code{\link[ingredients:partial_dependence]{ingredients::partial_dependency()}} and the coefficients of the adjusted linear model.}

\item{save_validateset}{save the validateset (independent data not used for training).}

\item{baseFilenameNN}{if no missing, save the NN in hdf5 format on this path with iteration appended.}

\item{filenameRasterPred}{if no missing, save the predictions in a RasterBrick to this file.}

\item{tempdirRaster}{path to a directory to save temporal raster files.}

\item{nCoresRaster}{number of cores used for parallelized raster cores. Use half of the available cores by default.}

\item{verbose}{If > 0, print state and passed to keras functions}

\item{...}{extra parameters for \code{\link[future.apply:future_lapply]{future.apply::future_replicate()}}  and \code{\link[ingredients:feature_importance]{ingredients::feature_importance()}}.}
}
\description{
Neural network model with keras
}
